{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from zipfile import ZipFile\n",
    "import glob\n",
    "import os\n",
    "import fitz\n",
    "import openai\n",
    "import pandas as pd\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_content(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'my_crawler (brandon.loorits@ut.ee) / for_study_purpose',\n",
    "    } # Määrame enda päringu päise, et oleks teada, kes päringuid veebileheküljele teeb\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f'Päring lehele {url} ebaõnnestus. Staatuskood: {response.status_code}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/shares\n"
     ]
    }
   ],
   "source": [
    "main_url = 'https://nasdaqbaltic.com/statistics/et/shares'\n",
    "shares = []\n",
    "\n",
    "# Kogume kokku kõik url-id\n",
    "print(f'Külastan lehte: {main_url}')\n",
    "time.sleep(5)  # Viiteaeg, et ei ummistaks lehte\n",
    "page_content = get_page_content(main_url)\n",
    "if page_content:\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    table = soup.find('table') \n",
    "    if table:\n",
    "        links = [a['href'] for a in table.find_all('a', href=True, class_=\"text16 compname\") if a['href'].startswith('/statistics/et/instrument')]\n",
    "        shares.extend(links)\n",
    "    else:\n",
    "        print('Ei leitud tabelit\".')\n",
    "else:\n",
    "    print('Algse lehe külastamine ebaõnnestus.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/statistics/et/instrument/LT0000128092/trading', '/statistics/et/instrument/LT0000102337/trading', '/statistics/et/instrument/EE3100034653/trading', '/statistics/et/instrument/LT0000127466/trading', '/statistics/et/instrument/EE3100007857/trading', '/statistics/et/instrument/LV0000101806/trading', '/statistics/et/instrument/EE3100016965/trading', '/statistics/et/instrument/EE3100127242/trading', '/statistics/et/instrument/EE3100137985/trading', '/statistics/et/instrument/LT0000102030/trading', '/statistics/et/instrument/EE3100004250/trading', '/statistics/et/instrument/EE3100082306/trading', '/statistics/et/instrument/LV0000101863/trading', '/statistics/et/instrument/LT0000115768/trading', '/statistics/et/instrument/EE3100149394/trading', '/statistics/et/instrument/LT0000111650/trading', '/statistics/et/instrument/EE3100102203/trading', '/statistics/et/instrument/EE3100098328/trading', '/statistics/et/instrument/EE3100039496/trading', '/statistics/et/instrument/LT0000131872/trading', '/statistics/et/instrument/EE3100006040/trading', '/statistics/et/instrument/EE3100101031/trading', '/statistics/et/instrument/LT0000101446/trading', '/statistics/et/instrument/LT0000111676/trading', '/statistics/et/instrument/LT0000100372/trading', '/statistics/et/instrument/LT0000102253/trading', '/statistics/et/instrument/LV0000101129/trading', '/statistics/et/instrument/EE3100001751/trading', '/statistics/et/instrument/EE3100004466/trading', '/statistics/et/instrument/LT0000123911/trading', '/statistics/et/instrument/EE0000001105/trading', '/statistics/et/instrument/EE3100021635/trading', '/statistics/et/instrument/EE3100026436/trading', '/statistics/et/instrument/LT0000127508/trading']\n"
     ]
    }
   ],
   "source": [
    "print(shares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/statistics/et/instrument/LT0000128092/reports?date=2024-04-24\n"
     ]
    }
   ],
   "source": [
    "page_content = get_page_content('https://nasdaqbaltic.com/statistics/et/instrument/LT0000128092/trading')\n",
    "soup = BeautifulSoup(page_content, 'html.parser')\n",
    "link_element = soup.find('a', string=\"Aruanded\")\n",
    "link = link_element.get('href')\n",
    "print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000128092/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000102337/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100034653/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000127466/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100007857/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LV0000101806/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100016965/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100127242/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100137985/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000102030/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100004250/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100082306/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LV0000101863/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000115768/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100149394/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000111650/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100102203/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100098328/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100039496/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000131872/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100006040/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100101031/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000101446/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000111676/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000100372/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000102253/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LV0000101129/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100001751/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100004466/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000123911/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE0000001105/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100021635/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100026436/trading\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000127508/trading\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "# Külastame leitud linke\n",
    "reports=[]\n",
    "for link in shares:\n",
    "    absolute_link = f'https://nasdaqbaltic.com{link}'\n",
    "    print(f'Külastan lehte: {absolute_link}')\n",
    "    time.sleep(5)  # Ootame 5 sekundit enne järgmise päringu tegemist, et mitte ummistada lehekülge\n",
    "    page_content = get_page_content(absolute_link)\n",
    "    if page_content:\n",
    "        soup = BeautifulSoup(page_content, 'html.parser')\n",
    "        link_element = soup.find('a', string=\"Aruanded\")\n",
    "        reports.append(link_element.get('href'))\n",
    "    else:\n",
    "        print(f'Lehe külastamine ebaõnnestus: {absolute_link}')\n",
    "print(len(reports))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/statistics/et/instrument/LV0000101806/reports?date=2024-04-24\n"
     ]
    }
   ],
   "source": [
    "print(reports[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ako', 'apg', 'ign', 'kne1', 'pzv', 'rsu', 'sab', 'vlp'])\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000128092/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/ako/2023_ar_en_eur_con_ias_esef.zip\n",
      "Kirjutame aastaaruande zipi ako_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000102337/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/apg/2023_ar_en_eur_con_ias_esef.zip\n",
      "Kirjutame aastaaruande zipi apg_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100034653/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/arc/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi arc_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000127466/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/aug/2022_ar_en_eur_con_ias.pdf\n",
      "Kirjutame aastaaruande pdfi aug_2022 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100007857/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/cpa/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi cpa_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LV0000101806/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/dgr/2022_ar_en_eur_con_ias.pdf\n",
      "Kirjutame aastaaruande pdfi dgr_2022 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100016965/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/eeg/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi eeg_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100127242/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/eft/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi eft_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100137985/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/egr/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi egr_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000102030/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/grg/2023_ar_en_eur_con_ias_esef.zip\n",
      "Kirjutame aastaaruande zipi grg_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100004250/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/hae/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi hae_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100082306/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/hpr/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi hpr_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LV0000101863/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/idx/2023_ar_en_eur_con_ias.pdf\n",
      "Kirjutame aastaaruande pdfi idx_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000115768/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/ign/2023_ar_en_eur_con_ias_esef.zip\n",
      "Kirjutame aastaaruande zipi ign_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100149394/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/inf/2022_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi inf_2022 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000111650/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/kne1/2023_ar_en_eur_con_ias_esef.zip\n",
      "Kirjutame aastaaruande zipi kne1_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100102203/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/lhv/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi lhv_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100098328/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/mrk/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi mrk_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100039496/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/ncn/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi ncn_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000131872/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/ntu/2022_ar_en_eur_con_ias.pdf\n",
      "Kirjutame aastaaruande pdfi ntu_2022 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100006040/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/pkg/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi pkg_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100101031/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/prf/2022_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi prf_2022 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000101446/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/ptr/2023_ar_en_eur_solo_ias.pdf\n",
      "Kirjutame aastaaruande pdfi ptr_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000111676/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/pzv/2023_ar_en_eur_solo_ias_esef.zip\n",
      "Kirjutame aastaaruande zipi pzv_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000100372/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/rsu/2023_ar_en_eur_con_ias_esef.zip\n",
      "Kirjutame aastaaruande zipi rsu_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000102253/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/sab/2023_ar_en_eur_con_ias_esef.zip\n",
      "Kirjutame aastaaruande zipi sab_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LV0000101129/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/saf/2023_ar_en_eur_con_ias.pdf\n",
      "Kirjutame aastaaruande pdfi saf_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100001751/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/sfg/2022_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi sfg_2022 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100004466/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/tal/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi tal_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000123911/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/tel1/2023_ar_en_eur_solo_ias.pdf\n",
      "Kirjutame aastaaruande pdfi tel1_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE0000001105/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/tkm/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi tkm_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100021635/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/tsm/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi tsm_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/EE3100026436/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/tve/2023_ar_et_eur_con_00.pdf\n",
      "Kirjutame aastaaruande pdfi tve_2023 maha\n",
      "Külastan lehte: https://nasdaqbaltic.com/statistics/et/instrument/LT0000127508/reports?date=2024-04-24\n",
      "REP link: https://nasdaqbaltic.com/market/upload/reports/vlp/2023_ar_en_eur_con_ias_esef.zip\n",
      "Kirjutame aastaaruande zipi vlp_2023 maha\n"
     ]
    }
   ],
   "source": [
    "base_link =f'https://nasdaqbaltic.com'\n",
    "xhtml_nums = {\n",
    "    'ako':('pf57','pf38_1'),\n",
    "    'apg':('pf1','pf2c'),\n",
    "    'ign':('pfa3','pf136'),\n",
    "    'kne1':('pfa3','pf100'),\n",
    "    'pzv':('pf57','pf70'),\n",
    "    'rsu':('pf1','pf34'),\n",
    "    'sab':('pf1','pf4c'),\n",
    "    'vlp':('pf1','pf4b')\n",
    "}\n",
    "exclusion_list = xhtml_nums.keys()\n",
    "# print(exclusion_list)\n",
    "# Loome kaustad, kui need ei eksisteeri\n",
    "os.makedirs('aruanded/aastaaruanded', exist_ok=True)\n",
    "os.makedirs('alusfailid', exist_ok=True)\n",
    "\n",
    "for report in reports:\n",
    "    absolute_link = f'{base_link}{report}'\n",
    "    print(f'Külastan lehte: {absolute_link}')\n",
    "    time.sleep(5)  # Ootame 5 sekundit enne järgmise päringu tegemist, et mitte ummistada lehekülge\n",
    "    page_content = get_page_content(absolute_link)\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    table = soup.find('tbody')\n",
    "\n",
    "    pdf_link = None\n",
    "    zip_link = None\n",
    "    esg_link = None\n",
    "\n",
    "    for row in table.find_all('tr'):\n",
    "        #print(row)\n",
    "        links = row.find_all('a')\n",
    "        hrefs = [link.get('href') for link in links]\n",
    "        #print(hrefs)\n",
    "        for href in hrefs:\n",
    "            # print(href)\n",
    "            if 'ar' in href.split('/')[-1] and href.endswith('.pdf') and href.split('/')[4] not in exclusion_list:\n",
    "                if href.split('/')[4] == 'dgr' and href.endswith('ias.pdf'): # erand ühele aruandele kuna sellel olemas ka lühendatud versioon, mida me ei vaja\n",
    "                    pdf_link = href\n",
    "                    break\n",
    "                else:\n",
    "                    pdf_link = href\n",
    "            elif 'ar' in href.split('/')[-1] and href.endswith('.zip') and not pdf_link:\n",
    "                zip_link = href\n",
    "            if 'esg' in href.split('/')[-1]:\n",
    "                esg_link = href\n",
    "        if pdf_link or zip_link:\n",
    "            break\n",
    "\n",
    "    # Kontrollime, kas aastaaruanne on olemas\n",
    "    if pdf_link:\n",
    "        # Kontrollime kõigepealt, kas ESG aruanne on olemas samale aastale\n",
    "        if esg_link:\n",
    "            esg_link_full = f'{base_link}{esg_link}'\n",
    "            print(f'ESG link: {esg_link_full}')\n",
    "            esg_response = requests.get(esg_link_full)\n",
    "            if esg_response:\n",
    "                match = re.search(r'/reports/([^_/]+/[^_/]+)_', esg_link_full).group(1).replace('/', '_')\n",
    "                print(f'Kirjutame esg {match} pdfi maha')\n",
    "                with open(f'aruanded/aastaaruanded/esg_{match}.pdf', 'wb') as file:\n",
    "                    file.write(esg_response.content)\n",
    "        else:# Kui ei ole, siis võtame href atribuudi väärtuse ja kirjutame aastaaruande kausta\n",
    "            rep_link = f'{base_link}{pdf_link}'\n",
    "            print(f'REP link: {rep_link}')\n",
    "                    \n",
    "            rep_response = requests.get(rep_link)\n",
    "            if rep_response:\n",
    "                match = re.search(r'/reports/([^_/]+/[^_/]+)_', rep_link).group(1).replace('/', '_')\n",
    "                print(f'Kirjutame aastaaruande pdfi {match} maha')\n",
    "                with open(f'aruanded/aastaaruanded/rep_{match}.pdf', 'wb') as file:\n",
    "                    file.write(rep_response.content)\n",
    "    elif zip_link:\n",
    "        # Võtame href atribuudi väärtuse\n",
    "        rep_link = f'{base_link}{zip_link}'\n",
    "        print(f'REP link: {rep_link}')\n",
    "                \n",
    "        rep_response = requests.get(rep_link)\n",
    "        if rep_response:\n",
    "            match = re.search(r'/reports/([^_/]+/[^_/]+)_', rep_link).group(1).replace('/', '_')\n",
    "            print(f'Kirjutame aastaaruande zipi {match} maha')\n",
    "            with open(f'alusfailid/rep_{match}.zip', 'wb') as file:\n",
    "                file.write(rep_response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leia_aruanne(zip_path, target_dir_rep):\n",
    "    # Kontrollime, kas väljundkaust on juba olemas\n",
    "    if not os.path.exists(target_dir_rep):\n",
    "        os.makedirs(target_dir_rep)\n",
    "    name = zip_path.split('\\\\')[1].replace('zip','xhtml')\n",
    "    with ZipFile(zip_path, 'r') as zip_ref:\n",
    "        for file_name in zip_ref.namelist():\n",
    "            # Kontrollime, kas faili laiend on .xhtml \n",
    "            if file_name.endswith('.xhtml'):\n",
    "                with zip_ref.open(file_name) as file:\n",
    "                    content = file.read()\n",
    "                    \n",
    "                new_file_path = os.path.join(target_dir_rep, os.path.basename(name))\n",
    "                print(new_file_path)\n",
    "                # Kirjutame sisu uude faili sihtkaustas\n",
    "                with open(new_file_path, 'wb') as new_file:\n",
    "                    new_file.write(content)\n",
    "                print(f\"Fail {os.path.basename(name)} on kirjutatud kausta {target_dir_rep}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aruanded/aruandedXHTML\\rep_ako_2023.xhtml\n",
      "Fail rep_ako_2023.xhtml on kirjutatud kausta aruanded/aruandedXHTML.\n",
      "aruanded/aruandedXHTML\\rep_apg_2023.xhtml\n",
      "Fail rep_apg_2023.xhtml on kirjutatud kausta aruanded/aruandedXHTML.\n",
      "aruanded/aruandedXHTML\\rep_grg_2023.xhtml\n",
      "Fail rep_grg_2023.xhtml on kirjutatud kausta aruanded/aruandedXHTML.\n",
      "aruanded/aruandedXHTML\\rep_ign_2023.xhtml\n",
      "Fail rep_ign_2023.xhtml on kirjutatud kausta aruanded/aruandedXHTML.\n",
      "aruanded/aruandedXHTML\\rep_kne1_2023.xhtml\n",
      "Fail rep_kne1_2023.xhtml on kirjutatud kausta aruanded/aruandedXHTML.\n",
      "aruanded/aruandedXHTML\\rep_pzv_2023.xhtml\n",
      "Fail rep_pzv_2023.xhtml on kirjutatud kausta aruanded/aruandedXHTML.\n",
      "aruanded/aruandedXHTML\\rep_rsu_2023.xhtml\n",
      "Fail rep_rsu_2023.xhtml on kirjutatud kausta aruanded/aruandedXHTML.\n",
      "aruanded/aruandedXHTML\\rep_sab_2023.xhtml\n",
      "Fail rep_sab_2023.xhtml on kirjutatud kausta aruanded/aruandedXHTML.\n",
      "aruanded/aruandedXHTML\\rep_vlp_2023.xhtml\n",
      "Fail rep_vlp_2023.xhtml on kirjutatud kausta aruanded/aruandedXHTML.\n"
     ]
    }
   ],
   "source": [
    "target_dir_rep = 'aruanded/aruandedXHTML'\n",
    "\n",
    "zip_files = glob.glob('alusfailid/*.zip')\n",
    "\n",
    "for zip in zip_files:\n",
    "    leia_aruanne(zip,target_dir_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_xhtml(xhtml_files, id_ranges):\n",
    "    for xhtml_file in xhtml_files:\n",
    "        file_name = xhtml_file.split('\\\\')[-1].split('.')[0].split('_')[1]\n",
    "        \n",
    "\n",
    "        if file_name in id_ranges:\n",
    "            start_id, end_id = id_ranges[file_name]\n",
    "            print(file_name)\n",
    "\n",
    "            with open(xhtml_file, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "\n",
    "            parsed_html = BeautifulSoup(content, 'lxml')\n",
    "            capture_text = False\n",
    "            extracted_text = \"\"\n",
    "\n",
    "            for div in parsed_html.find_all('div', id=True):\n",
    "                if div.get('id') == start_id:\n",
    "                    capture_text = True\n",
    "                if capture_text:\n",
    "                    extracted_text += div.get_text(separator=\"\\n\") + \"\\n\\n\"\n",
    "                    # print(extracted_text)\n",
    "                if div.get('id') == end_id:\n",
    "                    capture_text = False  \n",
    "            # Salvesta tekst txt faili\n",
    "            output_file_path = xhtml_file.replace('.xhtml', '.txt').replace('aruandedXHTML','aastaaruanded')\n",
    "            with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "                output_file.write(extracted_text)\n",
    "            print(f\"Text from {file_name}.xhtml between {start_id} and {end_id} has been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ako\n",
      "Text from ako.xhtml between pf57 and pf38_1 has been saved to aruanded/aastaaruanded\\rep_ako_2023.txt\n",
      "apg\n",
      "Text from apg.xhtml between pf1 and pf2c has been saved to aruanded/aastaaruanded\\rep_apg_2023.txt\n",
      "ign\n",
      "Text from ign.xhtml between pfa3 and pf136 has been saved to aruanded/aastaaruanded\\rep_ign_2023.txt\n",
      "kne1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brandon\\AppData\\Local\\anaconda3\\envs\\estnltk_env\\Lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from kne1.xhtml between pfa3 and pf100 has been saved to aruanded/aastaaruanded\\rep_kne1_2023.txt\n",
      "pzv\n",
      "Text from pzv.xhtml between pf57 and pf70 has been saved to aruanded/aastaaruanded\\rep_pzv_2023.txt\n",
      "rsu\n",
      "Text from rsu.xhtml between pf1 and pf34 has been saved to aruanded/aastaaruanded\\rep_rsu_2023.txt\n",
      "sab\n",
      "Text from sab.xhtml between pf1 and pf4c has been saved to aruanded/aastaaruanded\\rep_sab_2023.txt\n",
      "vlp\n",
      "Text from vlp.xhtml between pf1 and pf4b has been saved to aruanded/aastaaruanded\\rep_vlp_2023.txt\n"
     ]
    }
   ],
   "source": [
    "aruandedXHTML = glob.glob('aruanded/aruandedXHTML/*')\n",
    "\n",
    "extract_text_from_xhtml(aruandedXHTML, xhtml_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''Funktsioon loomaks sisukordade sõnastik'''\n",
    "def create_toc_dict(paths):\n",
    "    toc_dict = {}\n",
    "    for path in paths:\n",
    "        #print(path)\n",
    "        file_name = path.split('\\\\')[-1].split('.')[0].split('_')[1]\n",
    "        doc = fitz.open(path)\n",
    "        \n",
    "        toc_patterns = [\"sisukord\", \"table of contents\", \"content\", \"contents\"]\n",
    "\n",
    "        for page_num in range(len(doc)):\n",
    "            # print('PAGE NUMBER:',page_num+1)\n",
    "            text_lines = doc[page_num].get_text().splitlines()\n",
    "            for line in text_lines:\n",
    "                # print('RIDA:',line)\n",
    "                line = line.strip().lower() \n",
    "                for pattern in toc_patterns:\n",
    "                    if line == pattern.lower():\n",
    "                        toc_dict[file_name] = page_num\n",
    "                        break  # Leiame esimese vastavuse ja katkestame tsükli\n",
    "\n",
    "            if file_name in toc_dict:  # Kui oleme lehekülje leidnud, ei ole vaja edasi otsida\n",
    "                break\n",
    "    return toc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aruanded/aastaaruanded\\\\rep_dgr_2022.pdf']\n",
      "sisukorra lk nr: {'arc': 2, 'aug': 1, 'cpa': 2, 'dgr': 1, 'eeg': 2, 'eft': 2, 'egr': 1, 'hae': 2, 'hpr': 2, 'inf': 2, 'lhv': 3, 'mrk': 1, 'ncn': 2, 'ntu': 1, 'pkg': 2, 'prf': 2, 'saf': 1, 'sfg': 1, 'tal': 1, 'tel1': 1, 'tkm': 2, 'tsm': 2, 'tve': 1}\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "aastaaruanded = glob.glob('aruanded/aastaaruanded/*.pdf')\n",
    "toc = create_toc_dict(aastaaruanded)\n",
    "print(aastaaruanded[3:4])\n",
    "print('sisukorra lk nr:',toc)\n",
    "print(len(toc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sisukorra lk nr: {'arc': 2, 'aug': 1, 'cpa': 2, 'dgr': 1, 'eeg': 2, 'eft': 2, 'egr': 1, 'hae': 2, 'hpr': 2, 'inf': 2, 'lhv': 3, 'mrk': 1, 'ncn': 2, 'ntu': 1, 'pkg': 2, 'prf': 2, 'saf': 1, 'sfg': 1, 'tal': 1, 'tel1': 1, 'tkm': 2, 'tsm': 2, 'tve': 1}\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print('sisukorra lk nr:',toc)\n",
    "print(len(toc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_pdf_before_keyword_section(path, keywords, toc=None):\n",
    "    doc = fitz.open(path)\n",
    "    text_output_path = path.replace('.pdf', '.txt')\n",
    "    trim_start_page = None\n",
    "    file_name = path.split('\\\\')[-1].split('.')[0].split('_')[1]\n",
    "    nbr = toc.get(file_name)\n",
    "    # print(nbr)\n",
    "    if nbr is not None:\n",
    "        toc_text = doc[nbr].get_text().replace('\\n',' ')\n",
    "        # print(toc_text)\n",
    "        for keyword in keywords:\n",
    "            pattern = fr\"{re.escape(keyword)}\\s*(?:\\.+\\s*)+(\\d+)\"\n",
    "            #pattern = f\"{keyword}\\\\s*(\\\\d+)\"\n",
    "            # print('PATTERN',pattern)\n",
    "            match = re.search(pattern, toc_text, re.IGNORECASE)\n",
    "            #print(match)\n",
    "            if match:\n",
    "                trim_start_page = int(match.group(1)) - 1\n",
    "                #trim_start_page = 99\n",
    "                # print('LEITUD TEKST!!!!!!!!!!!:',trim_start_page)\n",
    "                break  \n",
    "\n",
    "    with open(text_output_path, \"w\", encoding=\"utf-8\") as text_file:\n",
    "        if trim_start_page is not None:\n",
    "            for page_num in range(trim_start_page):\n",
    "                page_text = doc[page_num].get_text()\n",
    "                text_file.write(page_text)\n",
    "        else:\n",
    "            for page_num in range(len(doc)):\n",
    "                page_text = doc[page_num].get_text()\n",
    "                text_file.write(page_text)\n",
    "\n",
    "    doc.close()\n",
    "    # print(trim_start_page)\n",
    "    return trim_start_page\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_arc_2023.pdf\n",
      "28\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_aug_2022.pdf\n",
      "77\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_cpa_2023.pdf\n",
      "40\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_dgr_2022.pdf\n",
      "None\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_eeg_2023.pdf\n",
      "91\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_eft_2023.pdf\n",
      "18\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_egr_2023.pdf\n",
      "None\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_hae_2023.pdf\n",
      "None\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_hpr_2023.pdf\n",
      "57\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_idx_2023.pdf\n",
      "None\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_inf_2022.pdf\n",
      "None\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_lhv_2023.pdf\n",
      "None\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_mrk_2023.pdf\n",
      "41\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_ncn_2023.pdf\n",
      "58\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_ntu_2022.pdf\n",
      "None\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_pkg_2023.pdf\n",
      "52\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_prf_2022.pdf\n",
      "30\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_ptr_2023.pdf\n",
      "None\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_saf_2023.pdf\n",
      "None\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_sfg_2022.pdf\n",
      "25\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_tal_2023.pdf\n",
      "61\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_tel1_2023.pdf\n",
      "None\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_tkm_2023.pdf\n",
      "50\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_tsm_2023.pdf\n",
      "None\n",
      "\n",
      "ARUANNE: aruanded/aastaaruanded\\rep_tve_2023.pdf\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "aastaaruanded = glob.glob('aruanded/aastaaruanded/*.pdf')\n",
    "\n",
    "keywords = ['Konsolideeritud raamatupidamise aastaaruanne',\n",
    "'Kontserni raamatupidamise aastaaruanne',\n",
    "'Konsolideerimisgrupi raamatupidamise aastaaruanne',\n",
    "'RAAMATUPIDAMISE AASTAARUANNE',\n",
    "'Consolidated and separate financial statements',\n",
    "'Financial Statements']\n",
    "cuts = {}\n",
    "for aruanne in aastaaruanded:\n",
    "    print()\n",
    "    print('ARUANNE:',aruanne)\n",
    "    file_name = aruanne.split('\\\\')[-1].split('.')[0].split('_')[1]\n",
    "    cut = trim_pdf_before_keyword_section(aruanne,keywords,toc)\n",
    "    print(cut)\n",
    "    cuts[file_name] = cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_problematic_pdf(path,cut):\n",
    "    doc = fitz.open(path)\n",
    "    text_output_path = path.replace('.pdf', '.txt')\n",
    "\n",
    "    with open(text_output_path, \"w\", encoding=\"utf-8\") as text_file:\n",
    "        for page_num in range(cut):\n",
    "            page_text = doc[page_num].get_text()\n",
    "            text_file.write(page_text)\n",
    "\n",
    "    doc.close()\n",
    "    # print(trim_start_page)\n",
    "    return text_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arc': 28, 'aug': 77, 'cpa': 40, 'dgr': None, 'eeg': 91, 'eft': 18, 'egr': None, 'hae': None, 'hpr': 57, 'idx': None, 'inf': None, 'lhv': None, 'mrk': 41, 'ncn': 58, 'ntu': None, 'pkg': 52, 'prf': 30, 'ptr': None, 'saf': None, 'sfg': 25, 'tal': 61, 'tel1': None, 'tkm': 50, 'tsm': None, 'tve': 107}\n",
      "25\n",
      "['egr', 'hae', 'inf', 'lhv', 'ntu', 'saf', 'tel1', 'tsm']\n"
     ]
    }
   ],
   "source": [
    "print(cuts)\n",
    "print(len(cuts))\n",
    "problematic_cuts = []\n",
    "for firm,cut in cuts.items():\n",
    "    if cut is None:\n",
    "        problematic_cuts.append(firm)\n",
    "problematic_cuts.remove('dgr') # eemaldame, sest sellel esg raport olemas\n",
    "problematic_cuts.remove('idx') # eemaldame, sest selle pdf vigane\n",
    "problematic_cuts.remove('ptr') # eemaldame, sest sellel esg raport olemas\n",
    "print(problematic_cuts)\n",
    "problematic_reports = {\n",
    "    'egr':89, \n",
    "    'hae':87, \n",
    "    'inf':14, \n",
    "    'lhv':81, \n",
    "    'ntu':41, \n",
    "    'saf':5, \n",
    "    'tel1':134, \n",
    "    'tsm':75\n",
    "}\n",
    "\n",
    "aastaaruanded = glob.glob('aruanded/aastaaruanded/*.pdf')\n",
    "\n",
    "for aruanne in aastaaruanded:\n",
    "    for firm,cut in problematic_reports.items():\n",
    "        if firm in aruanne:\n",
    "            trim_problematic_pdf(aruanne,cut)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_structure_text(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Eemaldame üleliigsed tühikud\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Liidame tükeldatud sõnad\n",
    "    text = re.sub(r'-\\s+', '', text)\n",
    "\n",
    "    # Eemaldame mitteolulised sümbolid gpt mudeli jaoks\n",
    "    # text = re.sub(r'[^a-zA-Z0-9.,;:!?()\"\\']+', ' ', text)\n",
    "\n",
    "    # Kirjutame faili sisu üle\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "aastaaruanded = glob.glob('aruanded/aastaaruanded/*.txt')\n",
    "\n",
    "for aruanne in aastaaruanded:\n",
    "    clean_and_structure_text(aruanne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brandon\\AppData\\Local\\anaconda3\\envs\\estnltk_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenite arv: {'aastaaruanded\\\\ako.txt': 108829, 'aastaaruanded\\\\apg.txt': 86013, 'aastaaruanded\\\\ign.txt': 121706, 'aastaaruanded\\\\kne1.txt': 34161, 'aastaaruanded\\\\pzv.txt': 4495, 'aastaaruanded\\\\rep_arc_2023.txt': 24883, 'aastaaruanded\\\\rep_aug_2022.txt': 40251, 'aastaaruanded\\\\rep_cpa_2023.txt': 44832, 'aastaaruanded\\\\rep_dgr_2022.txt': 45928, 'aastaaruanded\\\\rep_eeg_2023.txt': 102229, 'aastaaruanded\\\\rep_eft_2023.txt': 26620, 'aastaaruanded\\\\rep_egr_2023.txt': 108010, 'aastaaruanded\\\\rep_hae_2023.txt': 85999, 'aastaaruanded\\\\rep_hpr_2023.txt': 41715, 'aastaaruanded\\\\rep_idx_2023.txt': 6323, 'aastaaruanded\\\\rep_inf_2022.txt': 16119, 'aastaaruanded\\\\rep_lhv_2023.txt': 115726, 'aastaaruanded\\\\rep_mrk_2023.txt': 66892, 'aastaaruanded\\\\rep_ncn_2023.txt': 79380, 'aastaaruanded\\\\rep_ntu_2022.txt': 25903, 'aastaaruanded\\\\rep_pkg_2023.txt': 54259, 'aastaaruanded\\\\rep_prf_2022.txt': 33854, 'aastaaruanded\\\\rep_ptr_2023.txt': 5208, 'aastaaruanded\\\\rep_saf_2023.txt': 2803, 'aastaaruanded\\\\rep_sfg_2022.txt': 37407, 'aastaaruanded\\\\rep_tal_2023.txt': 55169, 'aastaaruanded\\\\rep_tel1_2023.txt': 63707, 'aastaaruanded\\\\rep_tkm_2023.txt': 74629, 'aastaaruanded\\\\rep_tsm_2023.txt': 63000, 'aastaaruanded\\\\rep_tve_2023.txt': 100804, 'aastaaruanded\\\\rsu.txt': 29180, 'aastaaruanded\\\\sab.txt': 73580, 'aastaaruanded\\\\vlp.txt': 51833}\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "txt_files = glob.glob('aruanded/aastaaruanded/*.txt')\n",
    "token_counts = {}\n",
    "\n",
    "\n",
    "for file_path in txt_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    cleaned_text = text\n",
    "    file_name = file_path.split('/')[-1]\n",
    "\n",
    "    tokens = tokenizer.tokenize(cleaned_text)\n",
    "    \n",
    "    token_counts[file_name] = len(tokens)\n",
    "\n",
    "print(f\"Tokenite arv: {token_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aastaaruanded\\ign.txt: 121706\n",
      "aastaaruanded\\rep_lhv_2023.txt: 115726\n",
      "aastaaruanded\\ako.txt: 108829\n",
      "aastaaruanded\\rep_egr_2023.txt: 108010\n",
      "aastaaruanded\\rep_eeg_2023.txt: 102229\n",
      "aastaaruanded\\rep_tve_2023.txt: 100804\n",
      "aastaaruanded\\apg.txt: 86013\n",
      "aastaaruanded\\rep_hae_2023.txt: 85999\n",
      "aastaaruanded\\rep_ncn_2023.txt: 79380\n",
      "aastaaruanded\\rep_tkm_2023.txt: 74629\n",
      "aastaaruanded\\sab.txt: 73580\n",
      "aastaaruanded\\rep_mrk_2023.txt: 66892\n",
      "aastaaruanded\\rep_tel1_2023.txt: 63707\n",
      "aastaaruanded\\rep_tsm_2023.txt: 63000\n",
      "aastaaruanded\\rep_tal_2023.txt: 55169\n",
      "aastaaruanded\\rep_pkg_2023.txt: 54259\n",
      "aastaaruanded\\vlp.txt: 51833\n",
      "aastaaruanded\\rep_dgr_2022.txt: 45928\n",
      "aastaaruanded\\rep_cpa_2023.txt: 44832\n",
      "aastaaruanded\\rep_hpr_2023.txt: 41715\n",
      "aastaaruanded\\rep_aug_2022.txt: 40251\n",
      "aastaaruanded\\rep_sfg_2022.txt: 37407\n",
      "aastaaruanded\\kne1.txt: 34161\n",
      "aastaaruanded\\rep_prf_2022.txt: 33854\n",
      "aastaaruanded\\rsu.txt: 29180\n",
      "aastaaruanded\\rep_eft_2023.txt: 26620\n",
      "aastaaruanded\\rep_ntu_2022.txt: 25903\n",
      "aastaaruanded\\rep_arc_2023.txt: 24883\n",
      "aastaaruanded\\rep_inf_2022.txt: 16119\n",
      "aastaaruanded\\rep_idx_2023.txt: 6323\n",
      "aastaaruanded\\rep_ptr_2023.txt: 5208\n",
      "aastaaruanded\\pzv.txt: 4495\n",
      "aastaaruanded\\rep_saf_2023.txt: 2803\n"
     ]
    }
   ],
   "source": [
    "sorted_token_counts = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for file_name, token_count in sorted_token_counts:\n",
    "    print(f\"{file_name}: {token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_data_path = os.getenv('ESG_INPUT')\n",
    "esg_data = pd.read_excel(esg_data_path)\n",
    "grouped_data = esg_data.groupby(['Topic', 'Question'])['Answers'].apply(list).reset_index()\n",
    "order_of_topics = [\n",
    "    'Stakeholder engagement and reporting',\n",
    "    'Leadership commitment', \n",
    "    'Impact assesment', \n",
    "    'Planning', \n",
    "    'Execution', \n",
    "    'Monitoring', \n",
    "    'Performance improvement', \n",
    "    'Across all topics'\n",
    "]\n",
    "\n",
    "grouped_data['Topic'] = pd.Categorical(grouped_data['Topic'], categories=order_of_topics, ordered=True)\n",
    "sorted_data = grouped_data.sort_values('Topic')\n",
    "sorted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_val_path = os.getenv('ESG_VAL')\n",
    "esg_val = pd.read_excel(esg_val_path)\n",
    "esg_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_text(row, answer_column):\n",
    "    if pd.notna(row[answer_column]):\n",
    "        answer_number = int(row[answer_column]) - 1 \n",
    "        if answer_number >= 0 and answer_number < len(row['Answers']):\n",
    "            return row['Answers'][answer_number]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = esg_val.merge(sorted_data, on='Question', how='left')\n",
    "merged_data['SS Explained'] = None\n",
    "merged_data['GPT Explained'] = None\n",
    "column_order = ['Company', 'Abbreviation','Topic', 'Question', 'SS Answer', 'SS Explained', 'GPT ANSWER 1','GPT Explained',  'Answers']\n",
    "merged_data = merged_data[column_order]\n",
    "\n",
    "merged_data['SS Explained'] = merged_data.apply(lambda row: get_answer_text(row, 'SS Answer'), axis=1)\n",
    "\n",
    "merged_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ako_data = merged_data[merged_data['Abbreviation'] == 'AKO']\n",
    "ako_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abbreviation: AKO\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "txt_files = glob.glob('aruanded/aastaaruanded/*ako.txt')\n",
    "\n",
    "for file in txt_files:\n",
    "    file_name = os.path.basename(file.replace('\\\\', '/')) \n",
    "    abbrev = file_name.split('.')[0]  \n",
    "    with open(file, 'r', encoding='utf-8') as file:\n",
    "        user_input_text = file.read()\n",
    "    print(\"Abbreviation:\", abbrev.upper())\n",
    "    for index, row in merged_data[merged_data['Abbreviation'] == abbrev.upper()].iterrows():\n",
    "        topic = row['Topic']\n",
    "        question = row['Question']\n",
    "        answers = [f\"{a}\" for a in row['Answers']] \n",
    "        # print('ANSWERS!!!-------',answers)\n",
    "        system_prompt = f\"Act as a sustainability specialist, who is filling in the pre-analysis questions based on the SASB methodology. \" \\\n",
    "                    f\"Firstly, focus to find the relevant parts of text based on the topic and then try to answer. \" \\\n",
    "                    f\"Choose one of the answer options, which is most suitable according to the provided report and give only the answer order number.\" \\\n",
    "                    f\"Give only one most accurate answer.\\n\\n\" \\\n",
    "                    f\"Topic: {topic}\\n\\n\" \\\n",
    "                    f\"Question: {question}\\n\\n\" \\\n",
    "                    f\"Answers:\\n\" + \"\\n\".join(answers)\n",
    "        system_prompts = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "                },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_input_text\n",
    "                }\n",
    "            ]\n",
    "        \n",
    "        #print(\"Request data:\")\n",
    "        #for message in system_prompts:\n",
    "            #print(f\"{message['role']}: {message['content']}\\n\")\n",
    "        # client = openai.OpenAI(api_key=os.getenv('MY_API_KEY'))\n",
    "        \n",
    "        # chat_completion = client.chat.completions.create(\n",
    "        #     messages=system_prompts,\n",
    "        #     model=\"gpt-4-turbo\",  \n",
    "        #     )\n",
    "\n",
    "        # contents = [choice['message']['content'] for choice in chat_completion['choices'] if choice['message']['role'] == 'assistant']\n",
    "        # merged_data.loc[index, 'GPT ANSWER 1'] = contents\n",
    "        answer = random.randint(1, 3)\n",
    "        merged_data.loc[index, 'GPT ANSWER 1'] = answer\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['First response.', 'Third response.']\n"
     ]
    }
   ],
   "source": [
    "chat_completion = {\n",
    "    'id': 'chatcmpl-9Gm2yzIdtAtyKTKoqVpv7OpVNlXLV',\n",
    "    'choices': [\n",
    "        {\n",
    "            'finish_reason': 'stop',\n",
    "            'index': 0,\n",
    "            'logprobs': None,\n",
    "            'message': {\n",
    "                'content': \"First response.\",\n",
    "                'role': 'assistant',\n",
    "                'function_call': None,\n",
    "                'tool_calls': None\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'finish_reason': 'stop',\n",
    "            'index': 1,\n",
    "            'logprobs': None,\n",
    "            'message': {\n",
    "                'content': \"Second response.\",\n",
    "                'role': 'system',\n",
    "                'function_call': None,\n",
    "                'tool_calls': None\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'finish_reason': 'stop',\n",
    "            'index': 2,\n",
    "            'logprobs': None,\n",
    "            'message': {\n",
    "                'content': \"Third response.\",\n",
    "                'role': 'assistant',\n",
    "                'function_call': None,\n",
    "                'tool_calls': None\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    'created': 1713784968,\n",
    "    'model': 'gpt-4-0125-preview',\n",
    "    'object': 'chat.completion',\n",
    "    'system_fingerprint': 'fp_122114e45f',\n",
    "    'usage': {\n",
    "        'completion_tokens': 17,\n",
    "        'prompt_tokens': 111067,\n",
    "        'total_tokens': 111084\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "contents = [choice['message']['content'] for choice in chat_completion['choices'] if choice['message']['role'] == 'assistant']\n",
    "\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9Gm2yzIdtAtyKTKoqVpv7OpVNlXLV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm sorry, but I cannot provide the answers to the disclosure questions as requested.\", role='assistant', function_call=None, tool_calls=None))], created=1713784968, model='gpt-4-0125-preview', object='chat.completion', system_fingerprint='fp_122114e45f', usage=CompletionUsage(completion_tokens=17, prompt_tokens=111067, total_tokens=111084))\n"
     ]
    }
   ],
   "source": [
    "# INPUT: report\n",
    "with open('aruanded/aastaaruanded/ako.txt', 'r', encoding='utf-8') as file:\n",
    "    user_input_text = file.read()\n",
    "\n",
    "for _, row in sorted_data.iterrows():\n",
    "    topic = row['Topic']\n",
    "    question = row['Question']\n",
    "    answers = [f\"{i+1}. {a.strip()}\" for i, a in enumerate(row['Answers'])] \n",
    "    # print('ANSWERS!!!-------',answers)\n",
    "    system_prompt = f\"Act as a sustainability specialist, who is filling in the pre-analysis questions based on the SASB methodology. \" \\\n",
    "                    f\"Firstly, focus to find the relevant parts from text based on the topic and then try to answer. \" \\\n",
    "                    f\"Choose one of the answer options, which is most suitable according to the provided report and give only the answer order number.\" \\\n",
    "                    f\"Give only one most accurate answer.\\n\\n\" \\\n",
    "                    f\"Topic: {topic}\\n\\n\" \\\n",
    "                    f\"Question: {question}\\n\\n\" \\\n",
    "                    f\"Answers:\\n\" + \"\\n\".join(answers)\n",
    "\n",
    "    system_prompts = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_input_text\n",
    "        }\n",
    "    ]\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv('MY_API_KEY'))\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=system_prompts,\n",
    "    model=\"gpt-4-turbo\",  \n",
    ")\n",
    "\n",
    "responses = []\n",
    "for message in chat_completion['choices'][0]['message']:\n",
    "    if message['role'] == 'assistant':\n",
    "        responses.append(message['content'])\n",
    "\n",
    "# Assuming each response is self-contained, create a DataFrame\n",
    "df = pd.DataFrame(responses, columns=['Responses'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def completion_with_backoff(**kwargs):\n",
    "    \"\"\"\n",
    "    Calls the OpenAI API with exponential backoff on retries. It will retry up to 6 times with increasing wait times.\n",
    "    \"\"\"\n",
    "    return openai.ChatCompletion.create(**kwargs)\n",
    "\n",
    "#https://cookbook.openai.com/examples/how_to_handle_rate_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mOpenAI(api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMY_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSay this is a test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m responses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m stream[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\brandon\\AppData\\Local\\anaconda3\\envs\\estnltk_env\\Lib\\site-packages\\openai\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\brandon\\AppData\\Local\\anaconda3\\envs\\estnltk_env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:667\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\brandon\\AppData\\Local\\anaconda3\\envs\\estnltk_env\\Lib\\site-packages\\openai\\_base_client.py:1213\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1201\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1208\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1210\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1211\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1212\u001b[0m     )\n\u001b[1;32m-> 1213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\brandon\\AppData\\Local\\anaconda3\\envs\\estnltk_env\\Lib\\site-packages\\openai\\_base_client.py:902\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    895\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    900\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    901\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\brandon\\AppData\\Local\\anaconda3\\envs\\estnltk_env\\Lib\\site-packages\\openai\\_base_client.py:978\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m    977\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\brandon\\AppData\\Local\\anaconda3\\envs\\estnltk_env\\Lib\\site-packages\\openai\\_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\brandon\\AppData\\Local\\anaconda3\\envs\\estnltk_env\\Lib\\site-packages\\openai\\_base_client.py:978\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m    977\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\brandon\\AppData\\Local\\anaconda3\\envs\\estnltk_env\\Lib\\site-packages\\openai\\_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\brandon\\AppData\\Local\\anaconda3\\envs\\estnltk_env\\Lib\\site-packages\\openai\\_base_client.py:993\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    990\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    992\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 993\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m    996\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    997\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1000\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1001\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv('MY_API_KEY'))\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "responses = []\n",
    "for message in stream['choices'][0]['message']:\n",
    "    if message['role'] == 'assistant':\n",
    "        responses.append(message['content'])\n",
    "\n",
    "df = pd.DataFrame(responses, columns=['Responses'])\n",
    "\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "estnltk_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
